{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM model tuner\n",
    "### Long Short Term Memory\n",
    "\n",
    "* Define functions\n",
    "* try to find the best hyperparameters\n",
    "* Train the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Input\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import Dropout\n",
    "import keras_tuner as kt\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "from math import sqrt\n",
    "from numpy import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.keras.layers.CuDNNLSTM\n",
    "\n",
    "def lstm_model_builder(hp):\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=['1e-2', '1e-3', '1e-4'])\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(hp.Int('input_unit',\n",
    "                        min_value=4,\n",
    "                        max_value=512,\n",
    "                        step=8), \n",
    "                        return_sequences=False, \n",
    "                        input_shape=(train_x.shape[1],train_x.shape[2])\n",
    "                        ))\n",
    "\n",
    "    # for i in range(hp.Int('n_layers', 1, 4)):\n",
    "    #     model.add(LSTM(hp.Int(f'lstm_{i}_units',min_value=32,max_value=512,step=4),return_sequences=True))\n",
    "\n",
    "    # model.add(LSTM(hp.Int('layer_2_neurons',min_value=32,max_value=512,step=4)))\n",
    "    # model.add(Dropout(hp.Float('Dropout_rate',min_value=0,max_value=0.5,step=0.1)))\n",
    "    model.add(Dense(train_y.shape[1], activation=hp.Choice('dense_activation',values=['relu', 'sigmoid'],default='relu')))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam',metrics = ['mse', 'mae'])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>co_ppb</th>\n",
       "      <th>o3_ppb</th>\n",
       "      <th>pm25_ugm3</th>\n",
       "      <th>so2_ugm3</th>\n",
       "      <th>temperatura_c</th>\n",
       "      <th>umidade_relativa_percentual</th>\n",
       "      <th>precipitacao_mmdia</th>\n",
       "      <th>focos_queimada</th>\n",
       "      <th>respiratory</th>\n",
       "      <th>avc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>135.40</td>\n",
       "      <td>11.125</td>\n",
       "      <td>8.175</td>\n",
       "      <td>0.875</td>\n",
       "      <td>26.450</td>\n",
       "      <td>81.75</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>155.05</td>\n",
       "      <td>10.925</td>\n",
       "      <td>11.675</td>\n",
       "      <td>1.000</td>\n",
       "      <td>26.400</td>\n",
       "      <td>82.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>137.40</td>\n",
       "      <td>12.225</td>\n",
       "      <td>8.800</td>\n",
       "      <td>0.825</td>\n",
       "      <td>27.400</td>\n",
       "      <td>81.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>128.30</td>\n",
       "      <td>13.750</td>\n",
       "      <td>11.650</td>\n",
       "      <td>0.925</td>\n",
       "      <td>27.750</td>\n",
       "      <td>76.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>128.25</td>\n",
       "      <td>10.950</td>\n",
       "      <td>7.800</td>\n",
       "      <td>1.075</td>\n",
       "      <td>26.625</td>\n",
       "      <td>84.75</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  co_ppb  o3_ppb  pm25_ugm3  so2_ugm3  temperatura_c  \\\n",
       "0 2013-01-01  135.40  11.125      8.175     0.875         26.450   \n",
       "1 2013-01-02  155.05  10.925     11.675     1.000         26.400   \n",
       "2 2013-01-03  137.40  12.225      8.800     0.825         27.400   \n",
       "3 2013-01-04  128.30  13.750     11.650     0.925         27.750   \n",
       "4 2013-01-05  128.25  10.950      7.800     1.075         26.625   \n",
       "\n",
       "   umidade_relativa_percentual  precipitacao_mmdia  focos_queimada  \\\n",
       "0                        81.75                 2.0             0.0   \n",
       "1                        82.00                 2.0             0.0   \n",
       "2                        81.25                 0.0             0.0   \n",
       "3                        76.25                 1.0             0.0   \n",
       "4                        84.75                 9.0             0.0   \n",
       "\n",
       "   respiratory  avc  \n",
       "0          6.0  1.0  \n",
       "1          8.0  0.0  \n",
       "2         12.0  1.0  \n",
       "3          9.0  0.0  \n",
       "4         10.0  1.0  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"../data/processed/new-avc.parquert\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"co_ppb\", \"so2_ugm3\", \"precipitacao_mmdia\", \"focos_queimada\", \"avc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(columns=[\"avc\"])\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply series_to_supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lags = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sl = series_to_supervised(scaled, n_in=n_lags, n_out=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns I don't want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sl.drop(df_sl.columns[[15, 16, 17, 18]], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and fit model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = df_sl.values\n",
    "train_set, test_set = train_test_split(\n",
    "    df_sl, test_size=0.2, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y = train_set.drop(\"var5(t)\", axis=1), train_set.drop(train_set.columns[:15], axis=1)\n",
    "test_X, test_Y = test_set.drop(\"var5(t)\", axis=1), test_set.drop(test_set.columns[:15], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape input to be 3D [samples, timesteps, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x = train_X.values, test_X.values\n",
    "train_y, test_y = train_Y.values, test_Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.reshape((train_x.shape[0], 1, train_x.shape[1]))\n",
    "test_x = test_x.reshape((test_x.shape[0], 1, test_x.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project ./2_lstm/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from ./2_lstm/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner= RandomSearch(\n",
    "        lstm_model_builder,\n",
    "        objective='mse',\n",
    "        max_trials=384,\n",
    "        executions_per_trial=2,\n",
    "        project_name = \"2_lstm\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "        x=train_x,\n",
    "        y=train_y,\n",
    "        epochs=50,\n",
    "        batch_size=128,\n",
    "        validation_data=(test_x,test_y),\n",
    "        callbacks=[TensorBoard(log_dir=\"logs/LSTM/2_tuner\"), callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat = best_model.predict(test_x)\n",
    "test_x = test_x.reshape((test_x.shape[0], test_x.shape[2]))\n",
    "yhat = yhat.reshape((yhat.shape[0], yhat.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 3.239\n"
     ]
    }
   ],
   "source": [
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((test_x[:, -4:], yhat), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,4]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_x[:, -4:], test_y), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,4]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:26:04) [GCC 10.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d04dcc92b7831af26710ec5ef30aede4a5b06cbc1a82f65de8264ec41d53735b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
